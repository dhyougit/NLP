{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOo2LItWDTlq0rexiBpDfb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhyougit/NLP/blob/main/Question_ResponseModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "ODxo7BPOVkJ5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDE3aD78VXi9",
        "outputId": "0a69a52e-72b1-4a7f-c4f8-7c2de3f3dac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 64)]              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3466 (13.54 KB)\n",
            "Trainable params: 3466 (13.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "# Method1: Sequential\n",
        "seq_model = Sequential()\n",
        "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
        "seq_model.add(layers.Dense(32, activation='relu'))\n",
        "seq_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# functional API\n",
        "input_tensor = Input(shape=(64,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(input_tensor, output_tensor)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 64))\n",
        "y_train = np.random.random((1000, 10))\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size = 128)\n",
        "\n",
        "score = model.evalutate(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "fnl5aLWCV2Zi",
        "outputId": "419a1163-18d9-4194-ace5-d31cad06d90b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 12.1300\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.4422\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.1502\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.2637\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.8115\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.7379\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 20.1741\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 23.0355\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 26.5233\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 30.4430\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f9f0f7e5c567>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'evalutate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API is particularly useful to build multi-type input model"
      ],
      "metadata": {
        "id": "jEkDe2OiV2bB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "embedd_text = layers.Embedding(\n",
        "    text_vocabulary_size, 64)(text_input)\n",
        "encoded_text = layers.LSTM(32)(embedd_text)\n",
        "\n",
        "question_input = Input(shape=(None,),\n",
        "                       dtype='int32',\n",
        "                       name='question')\n",
        "\n",
        "embedded_question = layers.Embedding(\n",
        "    question_vocabulary_size, 32)(question_input)\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
        "\n",
        "answer = layers.Dense(answer_vocabulary_size,\n",
        "                      activation='softmax')(concatenated)\n",
        "\n",
        "model = Model([text_input, question_input], answer)\n",
        "model.compile(optimizer = 'rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "s05USR0pV2dD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's inject data to the above model\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "text = np.random.randint(1, text_vocabulary_size,\n",
        "                         size=(num_samples, max_length))\n",
        "question = np.random.randint(1, question_vocabulary_size,\n",
        "                             size=(num_samples, max_length))\n",
        "\n",
        "answers = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
        "\n",
        "answers = to_categorical(answers)\n",
        "\n",
        "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
        "\n",
        "model.fit({'text':text, 'question':question}, answers,\n",
        "          epochs=10, batch_size=128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDSNHlJWV2ge",
        "outputId": "dd3d332d-2fa9-4c4b-f7b3-21b155d53d81"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 4s 117ms/step - loss: 6.2148 - accuracy: 0.0020\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 6.2098 - accuracy: 0.0070\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 6.2061 - accuracy: 0.0050\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 6.2021 - accuracy: 0.0080\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 6.1971 - accuracy: 0.0050\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 6.1888 - accuracy: 0.0060\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 143ms/step - loss: 6.1689 - accuracy: 0.0060\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 6.1341 - accuracy: 0.0060\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 6.0984 - accuracy: 0.0060\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 6.0690 - accuracy: 0.0060\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 3s 118ms/step - loss: 6.0448 - accuracy: 0.0020\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 6.0268 - accuracy: 0.0060\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 6.0117 - accuracy: 0.0060\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 6.0008 - accuracy: 0.0040\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 5.9924 - accuracy: 0.0070\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 2s 192ms/step - loss: 5.9862 - accuracy: 0.0070\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 2s 188ms/step - loss: 5.9805 - accuracy: 0.0070\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 5.9765 - accuracy: 0.0070\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.9726 - accuracy: 0.0070\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 5.9708 - accuracy: 0.0070\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ac86aaa3880>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCV5bDoRXKyQ",
        "outputId": "6ca2bb06-e65a-465f-b6d5-c70a6476db79"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6126, 3139, 3191, ...,  851, 2583,  783],\n",
              "       [4733, 9093, 3137, ..., 8640, 4410, 8352],\n",
              "       [ 831, 2409, 5485, ..., 1831,  144,  341],\n",
              "       ...,\n",
              "       [3302,  938, 5491, ..., 5610, 2792, 8657],\n",
              "       [4434, 1243, 2675, ..., 8655, 8139,  670],\n",
              "       [5518, 8919, 5070, ..., 4999, 4475, 1441]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vocabulary_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa0oPVDZjXyP",
        "outputId": "3f771ef1-528d-47c4-ba67-3eb69713d080"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "vocabulary_size = 50000\n",
        "num_income_groups = 10\n",
        "\n",
        "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
        "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
        "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "age_prediction = layers.Dense(1, name='age')(x)\n",
        "income_prediction = layers.Dense(num_income_groups,\n",
        "                                 activation='softmax',\n",
        "                                 name='income')(x)\n",
        "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
        "\n",
        "model = Model(posts_input,\n",
        "              [age_prediction, income_prediction, gender_prediction])"
      ],
      "metadata": {
        "id": "SqmE_bDLW05O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m9Uf314XW08m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LOvK_LzW09c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WSKHKoJtW0_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38M_UVyHW1B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DV1cjn4CW1Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oIJuIN--W1HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-e9Lm71eW1J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTPG28UDW1Me"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}